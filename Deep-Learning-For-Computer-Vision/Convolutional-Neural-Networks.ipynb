{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use 1x1 Convolutions to Manage Model Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling can be used to downsample the content of feature maps, reducing their width and height whilst maintaining their salient features. A problem with deep convolutional neural networks is that the number of feature maps often increases with the depth of the network. This problem can result in a dramatic increase in the number of parameters and computation required when larger filter sizes are used, such as 5 × 5 and 7 × 7.\n",
    "#### To address this problem, a 1 × 1 convolutional layer can be used that offers a channel-wise pooling, often called feature map pooling or a projection layer. This simple technique can be used for dimensionality reduction, decreasing the number of feature maps whilst retaining their salient features. It can also be used directly to create a one-to-one projection of the feature maps to pool features across channels or to increase the number of feature maps, such as after traditional pooling layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 512)     14336     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,336\n",
      "Trainable params: 14,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example of simple cnn model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu', input_shape=(256, 256, 3))) # summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Projecting Feature Maps\n",
    "\n",
    "* A 1 × 1 filter can be used to create a projection of the feature maps. The number of feature maps created will be the same number and the effect may be a refinement of the features already extracted. This is often called channel-wise pooling, as opposed to traditional feature-wise pooling on each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 512)     14336     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 256, 256, 512)     262656    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,992\n",
      "Trainable params: 276,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# example of simple cnn model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(Conv2D(512, (1,1), activation='relu'))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Decreasing Feature Maps\n",
    "\n",
    "* The 1 × 1 filter can be used to decrease the number of feature maps. This is the most common application of this type of filter and in this way, the layer is often called a feature map pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 256, 256, 512)     14336     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 256, 256, 64)      32832     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,168\n",
      "Trainable params: 47,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# example of simple cnn model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(Conv2D(64, (1,1), activation='relu'))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Increasing Feature Maps\n",
    "* The 1 × 1 filter can be used to increase the number of feature maps. This is a common operation used after a pooling layer prior to applying another convolutional layer. The projection effect of the filter can be applied as many times as needed to the input, allowing the number of feature maps to be scaled up and yet have a composition that captures the salient features of the original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 256, 256, 512)     14336     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 256, 256, 1024)    525312    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 539,648\n",
      "Trainable params: 539,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# example of simple cnn model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512, (3,3), padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(Conv2D(1024, (1,1), activation='relu'))\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Implement Model Architecture Innovations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 128, 128, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,720\n",
      "Trainable params: 38,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "# function for creating a vgg block\n",
    "def vgg_block(layer_in, n_filters, n_conv):\n",
    "  # add convolutional layers\n",
    "  for _ in range(n_conv):\n",
    "    layer_in = Conv2D(n_filters, (3,3), padding='same', activation='relu')(layer_in) \n",
    "  # add max pooling layer\n",
    "  layer_in = MaxPooling2D((2,2), strides=(2,2))(layer_in)\n",
    "  return layer_in\n",
    "# define model input\n",
    "visible = Input(shape=(256, 256, 3))\n",
    "# add vgg module\n",
    "layer = vgg_block(visible, 64, 2)\n",
    "# create model\n",
    "model = Model(inputs=visible, outputs=layer)\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 128, 128, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 64, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 32, 32, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,325,568\n",
      "Trainable params: 2,325,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of creating a CNN model with many VGG blocks\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "# function for creating a vgg block\n",
    "def vgg_block(layer_in, n_filters, n_conv):\n",
    "  # add convolutional layers\n",
    "  for _ in range(n_conv):\n",
    "    layer_in = Conv2D(n_filters, (3,3), padding='same', activation='relu')(layer_in) # add max pooling layer\n",
    "  layer_in = MaxPooling2D((2,2), strides=(2,2))(layer_in)\n",
    "  return layer_in\n",
    "# define model input\n",
    "visible = Input(shape=(256, 256, 3))\n",
    "# add vgg module\n",
    "layer = vgg_block(visible, 64, 2)\n",
    "# add vgg module\n",
    "layer = vgg_block(layer, 128, 2)\n",
    "# add vgg module\n",
    "layer = vgg_block(layer, 256, 4)\n",
    "# create model\n",
    "model = Model(inputs=visible, outputs=layer)\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use Pre-Trained Models and Transfer Learning\n",
    "\n",
    "### What Is Transfer Learning?\n",
    "\n",
    "* Transfer learning generally refers to a process where a model trained on one problem is used in some way on a second, related problem. In deep learning, transfer learning is a technique whereby a neural network model is first trained on a problem similar to the problem that is being solved. One or more layers from the trained model are then used in a new model trained on the problem of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH =\"/Users/test/Documents/Software-projects/Python Projects/Deep-Learning-Projects/Deep-Learning-Overfitting-Cook-Book/images/dog.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467096/553467096 [==============================] - 9s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 12:06:45.982788: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 318ms/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "35363/35363 [==============================] - 0s 1us/step\n",
      "Doberman (36.74%)\n"
     ]
    }
   ],
   "source": [
    "# example of using a pre-trained model as a classifier\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# load an image from file\n",
    "image = load_img(PATH, target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2])) # prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "# load the model\n",
    "model = VGG16()\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 360ms/step\n",
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "# example of using a pre-trained model as a classifier\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from pickle import dump\n",
    "# load an image from file\n",
    "image = load_img(PATH, target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2])) # prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "# load the model\n",
    "model = VGG16()\n",
    "model.layers.pop()\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "# get extracted features\n",
    "features = model.predict(image)\n",
    "print(features.shape)\n",
    "# save to file\n",
    "dump(features, open('dog.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
