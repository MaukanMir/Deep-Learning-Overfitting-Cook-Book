{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Language Modeling, or Language Modeling and LM for short, is the development of probabilistic models that are able to predict the next word in the sequence given the words that precede it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The neural network approach to language modeling can be described using the three following model properties, taken from A Neural Probabilistic Language Model, 2003.\n",
    "\n",
    "* Associate each word in the vocabulary with a distributed word feature vector.\n",
    "* Express the joint probability function of word sequences in terms of the feature vectors of these words in the sequence.\n",
    "* Learn simultaneously the word feature vector and the parameters of the probability function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Develop a Character-Based Neural Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/test/Documents/Software-projects/Python Projects/Deep-Learning-Projects/Deep-Learning-Overfitting-Cook-Book/data/rhyme.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sing a song of sixpence,\n",
      "A pocket full of rye.\n",
      "Four and twenty blackbirds,\n",
      "Baked in a pie.\n",
      "When the pie was opened The birds began to sing; Wasn't that a dainty dish, To set before the king.\n",
      "The king was in his counting house,\n",
      "Counting out his money;\n",
      "The queen was in the parlour,\n",
      "Eating bread and honey.\n",
      "The maid was in the garden,\n",
      "Hanging out the clothes,\n",
      "When down came a blackbird\n",
      "And pecked off her nose.\n",
      "Total Sequences: 399\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "  # open the file as read only \n",
    "  file = open(filename, 'r')\n",
    "  # read all text\n",
    "  text = file.read()\n",
    "  # close the file \n",
    "  file.close()\n",
    "  return text\n",
    "\n",
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename): \n",
    "  data = '\\n'.join(lines)\n",
    "  file = open(filename, 'w')\n",
    "  file.write(data)\n",
    "  file.close()\n",
    "\n",
    "# load text\n",
    "raw_text = load_doc(filename) \n",
    "print(raw_text)\n",
    "# clean\n",
    "tokens = raw_text.split() \n",
    "raw_text = ' '.join(tokens)\n",
    "# organize into sequences of characters\n",
    "length = 10\n",
    "sequences = list()\n",
    "for i in range(length, len(raw_text)):\n",
    "  # select sequence of tokens\n",
    "  seq = raw_text[i-length:i+1]\n",
    "  # store\n",
    "  sequences.append(seq)\n",
    "print('Total Sequences: %d' % len(sequences)) # save sequences to file\n",
    "out_filename = 'char_sequences.txt' \n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 38\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 75)                34200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 38)                2888      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,088\n",
      "Trainable params: 37,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\"dot\" with args ['-Tps', '/var/folders/d2/2759wj910z3_bl8zjx2l83tr0000gp/T/tmpggkml91s'] returned code: 1\n",
      "\n",
      "stdout, stderr:\n",
      " b''\n",
      "b'Format: \"ps\" not recognized. No formats found.\\nPerhaps \"dot -c\" needs to be run (with installer\\'s privileges) to register the plugins?\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\"dot\" with args ['-Tps', '/var/folders/d2/2759wj910z3_bl8zjx2l83tr0000gp/T/tmpggkml91s'] returned code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m y \u001b[38;5;241m=\u001b[39m to_categorical(y, num_classes\u001b[38;5;241m=\u001b[39mvocab_size)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# define model\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mdefine_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# fit model\u001b[39;00m\n\u001b[1;32m     52\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X, y, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m, in \u001b[0;36mdefine_model\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;66;03m# summarize defined model\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m---> 25\u001b[0m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniforge3/envs/machine-learning-env/lib/python3.8/site-packages/keras/utils/vis_utils.py:421\u001b[0m, in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m    417\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    418\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    419\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 421\u001b[0m dot \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_to_dot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_layer_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_layer_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrankdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrankdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpand_nested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_nested\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_layer_activations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_layer_activations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m to_file \u001b[38;5;241m=\u001b[39m io_utils\u001b[38;5;241m.\u001b[39mpath_to_string(to_file)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/machine-learning-env/lib/python3.8/site-packages/keras/utils/vis_utils.py:151\u001b[0m, in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph, layer_range, show_layer_activations)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sequential\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcheck_pydot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    152\u001b[0m   message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    153\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must install pydot (`pip install pydot`) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    154\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand install graphviz \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    155\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(see instructions at https://graphviz.gitlab.io/download/) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    156\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor plot_model/model_to_dot to work.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    157\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIPython.core.magics.namespace\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# We don't raise an exception here in order to avoid crashing notebook\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# tests where graphviz is not available.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/machine-learning-env/lib/python3.8/site-packages/keras/utils/vis_utils.py:51\u001b[0m, in \u001b[0;36mcheck_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;66;03m# Attempt to create an image of a blank graph\u001b[39;00m\n\u001b[1;32m     50\u001b[0m   \u001b[38;5;66;03m# to check the pydot/graphviz installation.\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m   \u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, pydot\u001b[38;5;241m.\u001b[39mInvocationException):\n",
      "File \u001b[0;32m~/miniforge3/envs/machine-learning-env/lib/python3.8/site-packages/pydot.py:1956\u001b[0m, in \u001b[0;36mDot.create\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1944\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1945\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{prog}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with args \u001b[39m\u001b[38;5;132;01m{arguments}\u001b[39;00m\u001b[38;5;124m returned code: \u001b[39m\u001b[38;5;132;01m{code}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1946\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout, stderr:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{out}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{err}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1952\u001b[0m         err\u001b[38;5;241m=\u001b[39mstderr_data,\n\u001b[1;32m   1953\u001b[0m     )\n\u001b[1;32m   1954\u001b[0m     \u001b[38;5;28mprint\u001b[39m(message)\n\u001b[0;32m-> 1956\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m process\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, (\n\u001b[1;32m   1957\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{prog}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with args \u001b[39m\u001b[38;5;132;01m{arguments}\u001b[39;00m\u001b[38;5;124m returned code: \u001b[39m\u001b[38;5;132;01m{code}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1958\u001b[0m             prog\u001b[38;5;241m=\u001b[39mprog,\n\u001b[1;32m   1959\u001b[0m             arguments\u001b[38;5;241m=\u001b[39marguments,\n\u001b[1;32m   1960\u001b[0m             code\u001b[38;5;241m=\u001b[39mprocess\u001b[38;5;241m.\u001b[39mreturncode,\n\u001b[1;32m   1961\u001b[0m         )\n\u001b[1;32m   1962\u001b[0m     )\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stdout_data\n",
      "\u001b[0;31mAssertionError\u001b[0m: \"dot\" with args ['-Tps', '/var/folders/d2/2759wj910z3_bl8zjx2l83tr0000gp/T/tmpggkml91s'] returned code: 1"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "  # open the file as read only \n",
    "  file = open(filename, 'r')\n",
    "  # read all text\n",
    "  text = file.read()\n",
    "  # close the file \n",
    "  file.close()\n",
    "  return text\n",
    "# define the model\n",
    "def define_model(X):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(75, input_shape=(X.shape[1], X.shape[2])))\n",
    "  model.add(Dense(vocab_size, activation='softmax'))\n",
    "  # compile model\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # summarize defined model\n",
    "  model.summary()\n",
    "  plot_model(model, to_file='model.png', show_shapes=True)\n",
    "  return model\n",
    "# load\n",
    "in_filename = 'char_sequences.txt'\n",
    "raw_text = load_doc(in_filename)\n",
    "lines = raw_text.split('\\n')\n",
    "# integer encode sequences of characters\n",
    "chars = sorted(list(set(raw_text)))\n",
    "mapping = dict((c, i) for i, c in enumerate(chars)) \n",
    "sequences = list()\n",
    "for line in lines:\n",
    "  # integer encode line\n",
    "  encoded_seq = [mapping[char] for char in line]\n",
    "  # store\n",
    "  sequences.append(encoded_seq)\n",
    "# vocabulary size\n",
    "vocab_size = len(mapping)\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "sequences = [to_categorical(x, num_classes=vocab_size) for x in X] \n",
    "X = array(sequences)\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "# define model\n",
    "model = define_model(X)\n",
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=2)\n",
    "# save the model to file\n",
    "model.save('model.h5')\n",
    "# save the mapping\n",
    "dump(mapping, open('mapping.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
